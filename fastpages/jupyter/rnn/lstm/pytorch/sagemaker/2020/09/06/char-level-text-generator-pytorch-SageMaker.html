<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Character-level Text Generator using Pytorch and Amazon SageMaker | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Character-level Text Generator using Pytorch and Amazon SageMaker" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions" />
<meta property="og:description" content="Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions" />
<link rel="canonical" href="https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html" />
<meta property="og:url" content="https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-06T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Character-level Text Generator using Pytorch and Amazon SageMaker","description":"Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions","datePublished":"2020-09-06T00:00:00-05:00","dateModified":"2020-09-06T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html"},"url":"https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/BlogEms/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://edumunozsala.github.io/BlogEms/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/BlogEms/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Character-level Text Generator using Pytorch and Amazon SageMaker | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Character-level Text Generator using Pytorch and Amazon SageMaker" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions" />
<meta property="og:description" content="Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions" />
<link rel="canonical" href="https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html" />
<meta property="og:url" content="https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-06T00:00:00-05:00" />
<script type="application/ld+json">
{"headline":"Character-level Text Generator using Pytorch and Amazon SageMaker","description":"Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions","datePublished":"2020-09-06T00:00:00-05:00","dateModified":"2020-09-06T00:00:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html"},"url":"https://edumunozsala.github.io/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://edumunozsala.github.io/BlogEms/feed.xml" title="fastpages" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/BlogEms/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/BlogEms/about/">About Me</a><a class="page-link" href="/BlogEms/search/">Search</a><a class="page-link" href="/BlogEms/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Character-level Text Generator using Pytorch and Amazon SageMaker</h1><p class="page-description">Implementing a simple LSTM encoder-decoder model with PyTorch to familiarize ourselves with the PyTorch library and Amazon SageMaker framework. We will cover how to use Amazon Sagemaker to train a model, deploy as an endpoint service and invoke it to get some predictions</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-06T00:00:00-05:00" itemprop="datePublished">
        Sep 6, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      41 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/BlogEms/categories/#fastpages">fastpages</a>
        &nbsp;
      
        <a class="category-tags-link" href="/BlogEms/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/BlogEms/categories/#RNN">RNN</a>
        &nbsp;
      
        <a class="category-tags-link" href="/BlogEms/categories/#LSTM">LSTM</a>
        &nbsp;
      
        <a class="category-tags-link" href="/BlogEms/categories/#Pytorch">Pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/BlogEms/categories/#SageMaker">SageMaker</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Character-level-text-generator-with-Pytorch">Character-level text generator with Pytorch </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Using-PyTorch-and-SageMaker">Using PyTorch and SageMaker </a></li>
<li class="toc-entry toc-h2"><a href="#General-Outline">General Outline </a></li>
<li class="toc-entry toc-h2"><a href="#Loading-the-libraries">Loading the libraries </a></li>
<li class="toc-entry toc-h2"><a href="#Step-1:-Downloading-and-loading-the-data">Step 1: Downloading and loading the data </a></li>
<li class="toc-entry toc-h2"><a href="#Step-2:-Preparing-and-Processing-the-data">Step 2: Preparing and Processing the data </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Cleaning-the-input-data">Cleaning the input data </a></li>
<li class="toc-entry toc-h3"><a href="#Creating-the-dictionary">Creating the dictionary </a></li>
<li class="toc-entry toc-h3"><a href="#Save-the-dictionary">Save the dictionary </a></li>
<li class="toc-entry toc-h3"><a href="#Create-the-input-data-and-labels-for-training">Create the input data and labels for training </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Step-3:-Upload-the-data-to-S3">Step 3: Upload the data to S3 </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Save-the-processed-training-dataset-locally">Save the processed training dataset locally </a></li>
<li class="toc-entry toc-h3"><a href="#Uploading-the-training-data">Uploading the training data </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Step-4:-Build-and-Train-the-PyTorch-Model">Step 4: Build and Train the PyTorch Model </a></li>
<li class="toc-entry toc-h2"><a href="#Create-a-batch-data-generator">Create a batch data generator </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Writing-the-training-method">Writing the training method </a></li>
<li class="toc-entry toc-h3"><a href="#Training-the-model">Training the model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Step-5:-Testing-the-model">Step 5: Testing the model </a></li>
<li class="toc-entry toc-h2"><a href="#Step-6---Deploy-the-model-for-inference">Step 6 - Deploy the model for inference </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Writing-inference-code">Writing inference code </a></li>
<li class="toc-entry toc-h3"><a href="#Deploying-the-model">Deploying the model </a></li>
<li class="toc-entry toc-h3"><a href="#Loading-a-previously-trained-model">Loading a previously trained model </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Step-7---Use-the-model-for-testing">Step 7 - Use the model for testing </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Delete-the-endpoint">Delete the endpoint </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-06-char-level-text-generator-pytorch-SageMaker.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Character-level-text-generator-with-Pytorch">
<a class="anchor" href="#Character-level-text-generator-with-Pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Character-level text generator with Pytorch<a class="anchor-link" href="#Character-level-text-generator-with-Pytorch"> </a>
</h1>
<h2 id="Using-PyTorch-and-SageMaker">
<a class="anchor" href="#Using-PyTorch-and-SageMaker" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using PyTorch and SageMaker<a class="anchor-link" href="#Using-PyTorch-and-SageMaker"> </a>
</h2>
<p>Some parts of the notebook have been extracted or modified from a notebook of my exercises in the Machine Learning Egineer Nanodegree.</p>
<p>In this notebook we will be implementing a simple RNN character model with PyTorch to familiarize ourselves with the PyTorch library and get started with RNNs. The goal is to build a model that can complete your sentence based on a few characters or a word used as input. And we will use AWS Sagemaker to train the model, evaluate and deploy.</p>
<h2 id="General-Outline">
<a class="anchor" href="#General-Outline" aria-hidden="true"><span class="octicon octicon-link"></span></a>General Outline<a class="anchor-link" href="#General-Outline"> </a>
</h2>
<p>Recall the general outline for SageMaker projects using a notebook instance.</p>
<ol>
<li>Download or otherwise retrieve the data.</li>
<li>Process / Prepare the data.</li>
<li>Upload the processed data to S3.</li>
<li>Train a chosen model.</li>
<li>Test the trained model (typically using a batch transform job).</li>
<li>Deploy the trained model.</li>
<li>Use the deployed model.</li>
</ol>
<p>For this project, you will be following the steps in the general outline with some modifications.</p>
<p>First, we will not be testing the model in its own step. We will still be testing the model, however, we will do it by deploying your model and then using the deployed model by sending the test data to it. One of the reasons for doing this is so that we can make sure that our deployed model is working correctly before moving forward.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-libraries">
<a class="anchor" href="#Loading-the-libraries" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading the libraries<a class="anchor-link" href="#Loading-the-libraries"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span> <span class="k">as</span> <span class="nn">rnd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-1:-Downloading-and-loading-the-data">
<a class="anchor" href="#Step-1:-Downloading-and-loading-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 1: Downloading and loading the data<a class="anchor-link" href="#Step-1:-Downloading-and-loading-the-data"> </a>
</h2>
<p>First, we'll define the sentences that we want our model to output when fed with the first word or the first few characters. Our dataset is a text file containing Shakespeare's plays or books from which we will extract sequence of chars to use as input to our model. Then our model will learn how to complete sentences like "Shakespeare would do".</p>
<p>This dataset can be downloaded from Karpathy's Github account: <a href="https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt">https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt</a>.</p>
<p>The dataset is stored in our notebook instance, it is small and easy to "move", so we do not need to store it in S3 or other cloud storage service.</p>
<p>As in many of my notebooks, we set some variables to the data directory and filenames. If you want to run this code on your own enviroment you must change these values:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Set the root folder</span>
<span class="n">root_folder</span><span class="o">=</span><span class="s1">'.'</span>
<span class="c1"># Set the folder with the dataset</span>
<span class="n">data_folder_name</span><span class="o">=</span><span class="s1">'data'</span>
<span class="n">model_folder_name</span><span class="o">=</span><span class="s1">'model'</span>
<span class="c1"># Set the filename</span>
<span class="n">filename</span><span class="o">=</span><span class="s1">'input.txt'</span>

<span class="c1"># Path to the data folder</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="n">data_folder_name</span><span class="p">))</span>
<span class="n">model_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="n">model_folder_name</span><span class="p">))</span>

<span class="c1"># Set the path where the text for training is stored</span>
<span class="n">train_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="c1"># Set a seed</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_text_data</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">init_dialog</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">''' Load the texts from the filename, splitting by lines and removing empty strings.</span>
<span class="sd">        Setting init_dialog = True will remove lines where the character who is going to speak is indicated</span>
<span class="sd">    '''</span>
    <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">reader</span><span class="p">:</span>
        <span class="c1">#sentences = reader.readlines()</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
            <span class="c1">#if ':' not in line and line !='\n':</span>
            <span class="k">if</span> <span class="n">init_dialog</span> <span class="ow">or</span> <span class="s1">':'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">line</span><span class="p">:</span>
                <span class="c1"># Append the line to the sentences, removing the end of line character</span>
                <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                
    <span class="k">return</span> <span class="n">sentences</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Loading the input data, sentences from Shakespeare's plays.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">load_text_data</span><span class="p">(</span><span class="n">train_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of sentences: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of sentences:  29723
['Before we proceed any further, hear me speak.', '', 'Speak, speak.', '', 'You are all resolved rather to die than to famish?', '', 'Resolved. resolved.', '', 'First, you know Caius Marcius is chief enemy to the people.', '', "We know't, we know't.", '', "Let us kill him, and we'll have corn at our own price.", "Is't a verdict?", '', '', 'One word, good citizens.', '', 'We are accounted poor citizens, the patricians good.', 'would yield us but the superfluity, while it were']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-2:-Preparing-and-Processing-the-data">
<a class="anchor" href="#Step-2:-Preparing-and-Processing-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 2: Preparing and Processing the data<a class="anchor-link" href="#Step-2:-Preparing-and-Processing-the-data"> </a>
</h2>
<p>Also, we will be doing some initial data processing. The first few steps are the same as in many other notebooks that works in NLP tasks. To begin with, we will read in each of the lines and combine them into a single input structure.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Cleaning-the-input-data">
<a class="anchor" href="#Cleaning-the-input-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning the input data<a class="anchor-link" href="#Cleaning-the-input-data"> </a>
</h3>
<p>When working with text data, we usually need to perform some cleanings to prepare the data for our algorithm. This time we will start with a simple cleaning, convert to lowercase the text and that's all.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">''' Cleaning process of the text'''</span>
    <span class="k">if</span> <span class="n">alpha</span><span class="p">:</span>
        <span class="c1"># Remove non alphabetic character</span>
        <span class="n">cleaned_text</span> <span class="o">=</span> <span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">t</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">or</span> <span class="n">t</span><span class="o">.</span><span class="n">isspace</span><span class="p">()])</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Simply lower the characters</span>
        <span class="n">cleaned_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
    <span class="c1"># Remove any emoty string</span>
    <span class="n">cleaned_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">cleaned_text</span> <span class="k">if</span> <span class="n">t</span><span class="o">!=</span><span class="s1">''</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">cleaned_text</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sentences</span> <span class="o">=</span> <span class="n">clean_text</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="c1"># Join all the sentences in a one long string</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of characters: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of characters:  894876
before we proceed any further, hear me speak. speak, speak. you are all resolved rather to die than 
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our input data is a sequence of 900,000 characters, we will extract the label data from this sequence and split it into a train and validation dataset. But we will do this tasks after encoding the text data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-the-dictionary">
<a class="anchor" href="#Creating-the-dictionary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating the dictionary<a class="anchor-link" href="#Creating-the-dictionary"> </a>
</h3>
<p>Now we'll create a dictionary out of all the characters that we have in the sentences and map them to an integer. This will allow us to convert our input characters to their respective integers (char2int) and viceversa (int2char).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CharVocab</span><span class="p">:</span> 
    <span class="sd">''' Create a Vocabulary for '''</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">type_vocab</span><span class="p">,</span><span class="n">pad_token</span><span class="o">=</span><span class="s1">'&lt;PAD&gt;'</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="s1">'&lt;EOS&gt;'</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">):</span> <span class="c1">#Initialization of the type of vocabulary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> <span class="n">type_vocab</span>
        <span class="c1">#self.int2char ={}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">int2char</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">pad_token</span> <span class="o">!=</span><span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">int2char</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pad_token</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">eos_token</span> <span class="o">!=</span><span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">int2char</span> <span class="o">+=</span> <span class="p">[</span><span class="n">eos_token</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">unk_token</span> <span class="o">!=</span><span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">int2char</span> <span class="o">+=</span> <span class="p">[</span><span class="n">unk_token</span><span class="p">]</span>
        <span class="c1">#self.int2char[1]=eos_token</span>
        <span class="c1">#self.int2char[2]=unk_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char2int</span> <span class="o">=</span> <span class="p">{}</span>
        
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>       <span class="c1">#When called, adds the values of parameters x_1 and x_2, prints and returns the result </span>
        <span class="c1"># Join all the sentences together and extract the unique characters from the combined sentences</span>
        <span class="n">chars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

        <span class="c1"># Creating a dictionary that maps integers to the characters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">int2char</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

        <span class="c1"># Creating another dictionary that maps characters to integers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char2int</span> <span class="o">=</span> <span class="p">{</span><span class="n">char</span><span class="p">:</span> <span class="n">ind</span> <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">int2char</span><span class="p">)}</span>
        
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">CharVocab</span><span class="p">(</span><span class="s1">'char'</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,</span><span class="s1">'&lt;UNK&gt;'</span><span class="p">)</span>
<span class="n">vocab</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Length of vocabulary: '</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">int2char</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Int to Char: '</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">int2char</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Char to Int: '</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">char2int</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Length of vocabulary:  38
Int to Char:  ['&lt;UNK&gt;', 'a', 'n', '-', 'h', '!', 'i', 'j', 'd', '.', 'f', 'x', 'k', 'w', '3', 'c', 'l', 'q', ' ', 'u', '&amp;', ',', '$', 't', 'b', 'm', 'p', ';', 'z', 'g', 'r', 's', '?', "'", 'e', 'v', 'o', 'y']
Char to Int:  {'&lt;UNK&gt;': 0, 'a': 1, 'n': 2, '-': 3, 'h': 4, '!': 5, 'i': 6, 'j': 7, 'd': 8, '.': 9, 'f': 10, 'x': 11, 'k': 12, 'w': 13, '3': 14, 'c': 15, 'l': 16, 'q': 17, ' ': 18, 'u': 19, '&amp;': 20, ',': 21, '$': 22, 't': 23, 'b': 24, 'm': 25, 'p': 26, ';': 27, 'z': 28, 'g': 29, 'r': 30, 's': 31, '?': 32, "'": 33, 'e': 34, 'v': 35, 'o': 36, 'y': 37}
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-the-dictionary">
<a class="anchor" href="#Save-the-dictionary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Save the dictionary<a class="anchor-link" href="#Save-the-dictionary"> </a>
</h3>
<p>In this example it is not mandatory to save the dictionary inmediately, because it is a fast and easy to reproduce task. But when dealing with a huge corpus and a large dictionary, we should save the dictionary to restore it latter when new experiments will be executed.</p>
<p>Later on when we construct an endpoint which processes a submitted review we will need to make use of the char2int and int2char dictionaries which we have created. As such, we will save them to a file now for future use.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Check or create the directory where dictionary will be saved</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">):</span> <span class="c1"># Make sure that the folder exists</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">)</span>
    
<span class="c1"># Save the dictionary to data path dir  </span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s1">'char_dict.pkl'</span><span class="p">),</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">char2int</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s1">'int_dict.pkl'</span><span class="p">),</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">int2char</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-the-input-data-and-labels-for-training">
<a class="anchor" href="#Create-the-input-data-and-labels-for-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create the input data and labels for training<a class="anchor-link" href="#Create-the-input-data-and-labels-for-training"> </a>
</h3>
<p>As we're going to predict the next character in the sequence at each time step, we'll have to divide each sentence into:</p>
<ul>
<li>
<strong>Input data</strong>: The last input character should be excluded as it does not need to be fed into the model (it is the target label for the last input character)</li>
<li>
<strong>Target/Ground Truth Label</strong>: One time-step ahead of the Input data as this will be the "correct answer" for the model at each time step corresponding to the input data</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dict_size</span><span class="p">):</span>
    <span class="sd">''' Define one hot encode matrix for our sequences'''</span>
    <span class="c1"># Creating a multi-dimensional array with the desired output shape</span>
    <span class="c1"># Encode every integer with its one hot representation</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">dict_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)[</span><span class="n">indices</span><span class="o">.</span><span class="n">flatten</span><span class="p">()]</span>
    
    <span class="c1"># Finally reshape it to get back to the original array</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">*</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dict_size</span><span class="p">))</span>
            
    <span class="k">return</span> <span class="n">features</span>

<span class="k">def</span> <span class="nf">encode_text</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="c1"># Replace every char by its integer value based on the vocabulary</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">char2int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">character</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">character</span> <span class="ow">in</span> <span class="n">input_text</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">one_hot</span><span class="p">:</span>
    <span class="c1"># One hot encode every integer of the sequence</span>
        <span class="n">dict_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">char2int</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dict_size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we can encode our text, replacing every character by the integer value in the dictionary. When we have our dataset unified and prepared, we should do a quick check and see an example of the data our model will be trained on. This is generally a good idea as it allows you to see how each of the further processing steps affects the reviews and it also ensures that the data has been loaded correctly.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Encode the train dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">encode_text</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">one_hot</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="c1"># Create the input sequence, from 0 to len-1</span>
<span class="n">input_seq</span><span class="o">=</span><span class="n">train_data</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># Create the target sequence, from 1 to len. It is right-shifted one place</span>
<span class="n">target_seq</span><span class="o">=</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Original text:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sentences</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Encoded text:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Input sequence:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">input_seq</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Target sequence:'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target_seq</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Original text:
before we proceed any further, hear me speak. speak, speak. you are all resolved rather to die than 

Encoded text:
[24 34 10 36 30 34 18 13 34 18 26 30 36 15 34 34  8 18  1  2 37 18 10 19
 30 23  4 34 30 21 18  4 34  1 30 18 25 34 18 31 26 34  1 12  9 18 31 26
 34  1 12 21 18 31 26 34  1 12  9 18 37 36 19 18  1 30 34 18  1 16 16 18
 30 34 31 36 16 35 34  8 18 30  1 23  4 34 30 18 23 36 18  8  6 34 18 23
  4  1  2 18]

Input sequence:
[24 34 10 36 30 34 18 13 34 18 26 30 36 15 34 34  8 18  1  2 37 18 10 19
 30 23  4 34 30 21 18  4 34  1 30 18 25 34 18 31 26 34  1 12  9 18 31 26
 34  1 12 21 18 31 26 34  1 12  9 18 37 36 19 18  1 30 34 18  1 16 16 18
 30 34 31 36 16 35 34  8 18 30  1 23  4 34 30 18 23 36 18  8  6 34 18 23
  4  1  2 18]

Target sequence:
[34 10 36 30 34 18 13 34 18 26 30 36 15 34 34  8 18  1  2 37 18 10 19 30
 23  4 34 30 21 18  4 34  1 30 18 25 34 18 31 26 34  1 12  9 18 31 26 34
  1 12 21 18 31 26 34  1 12  9 18 37 36 19 18  1 30 34 18  1 16 16 18 30
 34 31 36 16 35 34  8 18 30  1 23  4 34 30 18 23 36 18  8  6 34 18 23  4
  1  2 18 23]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets check our one-hot-encode function that we will use later during the training phase:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Encoded characters: '</span><span class="p">,</span><span class="n">train_data</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">102</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'One-hot-encoded characters: '</span><span class="p">,</span><span class="n">one_hot_encode</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">102</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">int2char</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Encoded characters:  [23 36]
One-hot-encoded characters:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-3:-Upload-the-data-to-S3">
<a class="anchor" href="#Step-3:-Upload-the-data-to-S3" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 3: Upload the data to S3<a class="anchor-link" href="#Step-3:-Upload-the-data-to-S3"> </a>
</h2>
<p>Now, we will need to upload the training dataset to S3 in order for our training code to access it. For now we will save it locally and we will upload to S3 later on.</p>
<h3 id="Save-the-processed-training-dataset-locally">
<a class="anchor" href="#Save-the-processed-training-dataset-locally" aria-hidden="true"><span class="octicon octicon-link"></span></a>Save the processed training dataset locally<a class="anchor-link" href="#Save-the-processed-training-dataset-locally"> </a>
</h3>
<p>It is important to note the format of the data that we are saving as we will need to know it when we write the training code. In our case, we will save the dataset as a pickle object, it is a list containing the whole dataset encoded as an integer value for every character.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Save the encoded text to a file</span>
<span class="n">encoded_data</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s1">'input_data.pkl'</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">encoded_data</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Uploading-the-training-data">
<a class="anchor" href="#Uploading-the-training-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Uploading the training data<a class="anchor-link" href="#Uploading-the-training-data"> </a>
</h3>
<p>Next, we need to upload the training data to the SageMaker default S3 bucket so that we can provide access to it while training our model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sagemaker</span>

<span class="c1"># Get the session id </span>
<span class="n">sagemaker_session</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c1"># Get the bucet, in our example the default buack</span>
<span class="n">bucket</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">default_bucket</span><span class="p">()</span>
<span class="c1"># Set the S3 subfolder where our data will be stored </span>
<span class="n">prefix</span> <span class="o">=</span> <span class="s1">'sagemaker/char_level_rnn'</span>
<span class="c1"># Get the role for permission</span>
<span class="n">role</span> <span class="o">=</span> <span class="n">sagemaker</span><span class="o">.</span><span class="n">get_execution_role</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_data</span> <span class="o">=</span> <span class="n">sagemaker_session</span><span class="o">.</span><span class="n">upload_data</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="n">bucket</span><span class="o">=</span><span class="n">bucket</span><span class="p">,</span> <span class="n">key_prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>NOTE:</strong> The cell above uploads the entire contents of our data directory. This includes the <code>char_dict.pkl</code> and <code>int_dict.pkl</code> file. This is fortunate as we will need this later on when we create an endpoint that accepts an arbitrary input text. For now, we will just take note of the fact that it resides in the data directory (and so also in the S3 training bucket) and that we will need to make sure it gets saved in the model directory.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-4:-Build-and-Train-the-PyTorch-Model">
<a class="anchor" href="#Step-4:-Build-and-Train-the-PyTorch-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 4: Build and Train the PyTorch Model<a class="anchor-link" href="#Step-4:-Build-and-Train-the-PyTorch-Model"> </a>
</h2>
<p>A model in the SageMaker framework, in particular, comprises three objects:</p>
<ul>
<li>Model Artifacts,</li>
<li>Training Code, and</li>
<li>Inference Code,</li>
</ul>
<p>each of which interact with one another.</p>
<p>We will start by implementing our own neural network in PyTorch along with a training script. For the purposes of this project we need to provide the model object implementation in the <code>model.py</code> file, inside of the <code>train</code> folder. You can see the provided implementation by running the cell below.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pygmentize train/model.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">torch</span>
<span class="ansi-blue-fg">from</span> <span class="ansi-cyan-fg ansi-underline">torch</span> <span class="ansi-blue-fg">import</span> nn
<span class="ansi-blue-fg">from</span> <span class="ansi-cyan-fg ansi-underline">torch</span><span class="ansi-cyan-fg ansi-underline">.</span><span class="ansi-cyan-fg ansi-underline">autograd</span> <span class="ansi-blue-fg">import</span> Variable

<span class="ansi-blue-fg">class</span> <span class="ansi-green-fg ansi-underline">RNNModel</span>(nn.Module):
    <span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">__init__</span>(<span class="ansi-cyan-fg">self</span>, vocab_size, embedding_size, hidden_dim, n_layers, drop_rate=<span class="ansi-blue-fg">0.2</span>):
        
        <span class="ansi-cyan-fg">super</span>(RNNModel, <span class="ansi-cyan-fg">self</span>).<span class="ansi-green-fg">__init__</span>()

        <span class="ansi-white-fg"># Defining some parameters</span>
        <span class="ansi-cyan-fg">self</span>.hidden_dim = hidden_dim
        <span class="ansi-cyan-fg">self</span>.embedding_size = embedding_size
        <span class="ansi-cyan-fg">self</span>.n_layers = n_layers
        <span class="ansi-cyan-fg">self</span>.vocab_size = vocab_size
        <span class="ansi-cyan-fg">self</span>.drop_rate = drop_rate
        <span class="ansi-cyan-fg">self</span>.char2int = <span class="ansi-blue-fg">None</span>
        <span class="ansi-cyan-fg">self</span>.int2char = <span class="ansi-blue-fg">None</span>


        <span class="ansi-white-fg">#Defining the layers</span>
        <span class="ansi-white-fg"># Define the encoder as an Embedding layer</span>
        <span class="ansi-white-fg">#self.encoder = nn.Embedding(vocab_size, embedding_size)</span>
            
        <span class="ansi-white-fg"># Dropout layer</span>
        <span class="ansi-cyan-fg">self</span>.dropout = nn.Dropout(drop_rate)
        <span class="ansi-white-fg"># RNN Layer</span>
        <span class="ansi-cyan-fg">self</span>.rnn = nn.LSTM(embedding_size, hidden_dim, n_layers, dropout=drop_rate, batch_first = <span class="ansi-blue-fg">True</span>)
        <span class="ansi-white-fg"># Fully connected layer</span>
        <span class="ansi-cyan-fg">self</span>.decoder = nn.Linear(hidden_dim, vocab_size)
    
    <span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">forward</span>(<span class="ansi-cyan-fg">self</span>, x, state):
        
        <span class="ansi-white-fg"># input shape: [batch_size, seq_len, embedding_size]</span>
        <span class="ansi-white-fg"># Apply the embedding layer and dropout</span>
        <span class="ansi-white-fg">#embed_seq = self.dropout(self.encoder(x))</span>
            
        <span class="ansi-white-fg">#print('Input RNN shape: ', embed_seq.shape)</span>
        <span class="ansi-white-fg"># shape: [batch_size, seq_len, embedding_size]</span>
        rnn_out, state = <span class="ansi-cyan-fg">self</span>.rnn(x, state)
        <span class="ansi-white-fg">#print('Out RNN shape: ', rnn_out.shape)</span>
        <span class="ansi-white-fg"># rnn_out shape: [batch_size, seq_len, rnn_size]</span>
        <span class="ansi-white-fg"># hidden shape: [2, num_layers, batch_size, rnn_size]</span>
        rnn_out = <span class="ansi-cyan-fg">self</span>.dropout(rnn_out)

        <span class="ansi-white-fg"># shape: [seq_len, batch_size, rnn_size]</span>
        <span class="ansi-white-fg"># Stack up LSTM outputs using view</span>
        <span class="ansi-white-fg"># you may need to use contiguous to reshape the output</span>
        rnn_out = rnn_out.contiguous().view(-<span class="ansi-blue-fg">1</span>, <span class="ansi-cyan-fg">self</span>.hidden_dim)

        logits = <span class="ansi-cyan-fg">self</span>.decoder(rnn_out)
        <span class="ansi-white-fg"># output shape: [seq_len * batch_size, vocab_size]</span>
        <span class="ansi-white-fg">#print('Output model shape: ', logits.shape)</span>
        <span class="ansi-blue-fg">return</span> logits, state
    
    <span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">init_state</span>(<span class="ansi-cyan-fg">self</span>, device, batch_size=<span class="ansi-blue-fg">1</span>):
        <span class="ansi-yellow-fg">"""</span>
<span class="ansi-yellow-fg">        initialises rnn states.</span>
<span class="ansi-yellow-fg">        """</span>
        <span class="ansi-white-fg">#return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim)),</span>
        <span class="ansi-white-fg">#        Variable(torch.zeros(self.n_layers, batch_size, self.hidden_dim)))</span>
        <span class="ansi-blue-fg">return</span> (torch.zeros(<span class="ansi-cyan-fg">self</span>.n_layers, batch_size, <span class="ansi-cyan-fg">self</span>.hidden_dim).to(device),
                torch.zeros(<span class="ansi-cyan-fg">self</span>.n_layers, batch_size, <span class="ansi-cyan-fg">self</span>.hidden_dim).to(device))

    <span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">predict</span>(<span class="ansi-cyan-fg">self</span>, <span class="ansi-cyan-fg">input</span>):
        <span class="ansi-white-fg"># input shape: [seq_len, batch_size]</span>
        logits, hidden = <span class="ansi-cyan-fg">self</span>.forward(<span class="ansi-cyan-fg">input</span>)
        <span class="ansi-white-fg"># logits shape: [seq_len * batch_size, vocab_size]</span>
        <span class="ansi-white-fg"># hidden shape: [2, num_layers, batch_size, rnn_size]</span>
        probs = F.softmax(logits)
        <span class="ansi-white-fg"># shape: [seq_len * batch_size, vocab_size]</span>
        probs = probs.view(<span class="ansi-cyan-fg">input</span>.size(<span class="ansi-blue-fg">0</span>), <span class="ansi-cyan-fg">input</span>.size(<span class="ansi-blue-fg">1</span>), probs.size(<span class="ansi-blue-fg">1</span>))
        <span class="ansi-white-fg"># output shape: [seq_len, batch_size, vocab_size]</span>
        <span class="ansi-blue-fg">return</span> probs, hidden
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Create-a-batch-data-generator">
<a class="anchor" href="#Create-a-batch-data-generator" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create a batch data generator<a class="anchor-link" href="#Create-a-batch-data-generator"> </a>
</h2>
<p>When training on the dataset, we need to extract a batch size examples from the inputs and targets, forward and backward the RNN on them and then repite the iteration with another batch size examples. A batch generator will help us to extract a batch size examples from our datasets.</p>
<p>The next code defines our batch generator:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">batch_generator_sequence</span><span class="p">(</span><span class="n">features_seq</span><span class="p">,</span> <span class="n">label_seq</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">):</span>
    <span class="sd">"""Generator function that yields batches of data (input and target)</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_size (int): number of examples (in this case, sentences) per batch.</span>
<span class="sd">        max_length (int): maximum length of the output tensor.</span>
<span class="sd">        NOTE: max_length includes the end-of-sentence character that will be added</span>
<span class="sd">                to the tensor.  </span>
<span class="sd">                Keep in mind that the length of the tensor is always 1 + the length</span>
<span class="sd">                of the original line of characters.</span>
<span class="sd">        input_lines (list): list of the input data to group into batches.</span>
<span class="sd">        target_lines (list): list of the target data to group into batches.</span>
<span class="sd">        shuffle (bool, optional): True if the generator should generate random batches of data. Defaults to True.</span>

<span class="sd">    Yields:</span>
<span class="sd">        tuple: two copies of the batch and the mask </span>
<span class="sd">    """</span>
    <span class="c1"># calculate the number of batches we can supply</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features_seq</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_len</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_batches</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"No batches created. Use smaller batch size or sequence length."</span><span class="p">)</span>
    <span class="c1"># calculate effective length of text to use</span>
    <span class="n">rounded_len</span> <span class="o">=</span> <span class="n">num_batches</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_len</span>
    <span class="c1"># Reshape the features matrix in batch size x num_batches * seq_len</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_seq</span><span class="p">[:</span> <span class="n">rounded_len</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_batches</span> <span class="o">*</span> <span class="n">seq_len</span><span class="p">])</span>
    
    <span class="c1"># Reshape the target matrix in batch size x num_batches * seq_len</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">label_seq</span><span class="p">[:</span> <span class="n">rounded_len</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_batches</span> <span class="o">*</span> <span class="n">seq_len</span><span class="p">])</span>
    
    <span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># roll so that no need to reset rnn states over epochs</span>
        <span class="n">x_epoch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">epoch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y_epoch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="n">epoch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">x_epoch</span><span class="p">[</span><span class="n">batch</span><span class="p">],</span> <span class="n">y_epoch</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Writing-the-training-method">
<a class="anchor" href="#Writing-the-training-method" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing the training method<a class="anchor-link" href="#Writing-the-training-method"> </a>
</h3>
<p>Next we need to write the training code itself. This should be very similar to training methods that you have written before to train PyTorch models. We will leave any difficult aspects such as model saving / loading and parameter loading until a little later.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_main</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">val_batches</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">clip_norm</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="c1"># Training Run</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="c1"># Store the loss in every batch iteration</span>
        <span class="n">epoch_losses</span> <span class="o">=</span><span class="p">[]</span>
        <span class="c1"># Init the hidden state</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># Train all the batches in every epoch</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="o">-</span><span class="n">val_batches</span><span class="p">):</span>
            <span class="c1">#print('Batch :', i)</span>
            <span class="c1"># Get the next batch data for input and target</span>
            <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="c1"># Onr hot encode the input data</span>
            <span class="n">input_batch</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="c1"># Tranform to tensor</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">)</span>
            <span class="c1"># Create a new variable for the hidden state, necessary to calculate the gradients</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(([</span><span class="n">Variable</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">hidden</span><span class="p">]))</span>
            <span class="c1"># Move the input data to the device</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1">#print('Input shape: ', input_data.shape)</span>
            <span class="c1">#print('Hidden shape: ', hidden[0].shape, hidden[1].shape)</span>
            <span class="c1"># Set the model to train and prepare the gradients</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># Clears existing gradients from previous epoch</span>
            <span class="c1"># Pass Fordward the RNN</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="c1">#print('Output shape: ', output.shape)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1">#print('Output shape: ', output.shape)</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="c1"># Move the target data to the device</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">target_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">seq_len</span><span class="p">,))</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">seq_len</span><span class="p">))</span>
            <span class="c1">#print(loss)</span>
            <span class="c1"># Save the loss</span>
            <span class="n">epoch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1">#data[0]</span>
        
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Does backpropagation and calculates gradients</span>
            <span class="c1"># clip gradient norm</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip_norm</span><span class="p">)</span>
            
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># Updates the weights accordingly</span>
    
        <span class="c1"># Now, when epoch is finished, evaluate the model on validation data</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">val_batches</span><span class="p">):</span>
            <span class="c1"># Get the next batch data for input and target</span>
            <span class="n">input_batch</span><span class="p">,</span> <span class="n">target_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="c1"># Onr hot encode the input data</span>
            <span class="n">input_batch</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="c1"># Tranform to tensor</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">)</span>
            <span class="c1"># Create a new variable for the hidden state, necessary to calculate the gradients</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(([</span><span class="n">Variable</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">val_hidden</span><span class="p">]))</span>
            <span class="c1"># Move the input data to the device</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1"># Pass Fordward the RNN</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            <span class="c1">#print('Output shape: ', output.shape)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1">#print('Output shape: ', output.shape)</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="c1"># Move the target data to the device</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">target_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="n">target_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">seq_len</span><span class="p">,))</span>
            <span class="c1">#print('Target shape; ', target_data.shape)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">seq_len</span><span class="p">))</span>
            <span class="c1">#print(loss)</span>
            <span class="c1"># Save the loss</span>
            <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1">#data[0]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>                  
        <span class="c1">#if epoch%2 == 0:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">.............'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Time: </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Train Loss: </span><span class="si">{:.4f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s1">' '</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Val Loss: </span><span class="si">{:.4f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)))</span>
        
    <span class="k">return</span> <span class="n">epoch_losses</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Supposing we have the training method above, we will test that it is working by writing a bit of code in the notebook that executes our training method on a small sample training set. Because we are not using a GPU and we are just testing the training code we take 50,000 characters from the input data. The reason for doing this in the notebook is so that we have an opportunity to fix any errors that arise early when they are easier to diagnose.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">train.model</span> <span class="kn">import</span> <span class="n">RNNModel</span>

<span class="c1"># Set a seed to reproduce experiments</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="c1"># Set the device for training</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># Create the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="mi">38</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define Loss, Optimizer</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Limit the size of our input sequence for this simple test</span>
<span class="n">input_seq</span> <span class="o">=</span> <span class="n">input_seq</span><span class="p">[:</span><span class="mi">50000</span><span class="p">]</span>
<span class="n">target_seq</span> <span class="o">=</span> <span class="n">target_seq</span><span class="p">[:</span><span class="mi">50000</span><span class="p">]</span>

<span class="c1"># Calculate the number of batches to train</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">maxlen</span><span class="o">=</span><span class="mi">64</span>
<span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span> <span class="o">//</span> <span class="p">(</span><span class="n">batch_size</span><span class="o">*</span><span class="n">maxlen</span><span class="p">)</span>
<span class="c1"># Calculate the validation batches</span>
<span class="n">val_frac</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">val_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_batches</span><span class="o">*</span><span class="n">val_frac</span><span class="p">)</span>

<span class="c1"># Create the batch data generator</span>
<span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_generator_sequence</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">)</span>
<span class="c1"># Train the model</span>
<span class="n">losses</span> <span class="o">=</span> <span class="n">train_main</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">val_batches</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch: 1/5............. Time: 0.3447 Train Loss: 3.2359 Val Loss: 2.9530
Epoch: 2/5............. Time: 0.3499 Train Loss: 2.9400 Val Loss: 2.8528
Epoch: 3/5............. Time: 0.3474 Train Loss: 2.7989 Val Loss: 2.6553
Epoch: 4/5............. Time: 0.3487 Train Loss: 2.6213 Val Loss: 2.4888
Epoch: 5/5............. Time: 0.3474 Train Loss: 2.5100 Val Loss: 2.3986
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to construct a PyTorch model using SageMaker we must provide SageMaker with a training script. We may optionally include a directory which will be copied to the container and from which our training code will be run. When the training container is executed it will check the uploaded directory (if there is one) for a <code>requirements.txt</code> file and install any required Python libraries, after which the training script will be run.</p>
<p>In this example, we only requiere the numpy package.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-the-model">
<a class="anchor" href="#Training-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training the model<a class="anchor-link" href="#Training-the-model"> </a>
</h3>
<p>When a PyTorch model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained. Inside of the <code>train</code> directory is a file called <code>train.py</code> which contains most of the necessary code to train our model.</p>
<p><strong>NOTICE</strong>: The <code>train()</code> method written above and has been pasted into the <code>train/train.py</code> file where required.</p>
<p>The way that SageMaker passes hyperparameters to the training script is by way of arguments. These arguments can then be parsed and used in the training script. To see how this is done take a look at the provided <code>train/train.py</code> file.</p>
<p>First, we need to set which type of instance will run our training:</p>
<ul>
<li>Local: We do not launch a real compute instance, just a container where our scripts will run. This scenario is very useful to test that the train script is working fine because it is faster to run a container than an compute instance. But finally, when we confirm that everything is working we must change the instance type for a "real" training instance.</li>
<li>ml.m4.4xlarge: It is a CPU instance</li>
<li>ml.p2.xlarge: A GPU instance to use when managing a big volume of data to train on.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Select the type of instance to use for training</span>
<span class="c1">#instance_type='ml.m4.4xlarge' # CPU instance</span>
<span class="n">instance_type</span><span class="o">=</span><span class="s1">'ml.p2.xlarge'</span> <span class="c1"># GPU instance</span>
<span class="c1">#instance_type='local'</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sagemaker.pytorch</span> <span class="kn">import</span> <span class="n">PyTorch</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">PyTorch</span><span class="p">(</span><span class="n">entry_point</span><span class="o">=</span><span class="s2">"train.py"</span><span class="p">,</span>
                    <span class="n">source_dir</span><span class="o">=</span><span class="s2">"train"</span><span class="p">,</span>
                    <span class="n">role</span><span class="o">=</span><span class="n">role</span><span class="p">,</span>
                    <span class="n">framework_version</span><span class="o">=</span><span class="s1">'0.4.0'</span><span class="p">,</span>
                    <span class="n">train_instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">train_instance_type</span><span class="o">=</span><span class="n">instance_type</span><span class="p">,</span>
                    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
                        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
                        <span class="s1">'hidden_dim'</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
                        <span class="s1">'n_layers'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">({</span><span class="s1">'training'</span><span class="p">:</span> <span class="n">input_data</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.
's3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.
'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2020-09-04 18:09:13 Starting - Starting the training job...
2020-09-04 18:09:15 Starting - Launching requested ML instances......
2020-09-04 18:10:30 Starting - Preparing the instances for training.........
2020-09-04 18:12:11 Downloading - Downloading input data......
2020-09-04 18:13:01 Training - Downloading the training image..<span class="ansi-blue-fg">bash: cannot set terminal process group (-1): Inappropriate ioctl for device</span>
<span class="ansi-blue-fg">bash: no job control in this shell</span>
<span class="ansi-blue-fg">2020-09-04 18:13:23,643 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training</span>
<span class="ansi-blue-fg">2020-09-04 18:13:23,671 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.</span>
<span class="ansi-blue-fg">2020-09-04 18:13:26,690 sagemaker_pytorch_container.training INFO     Invoking user training script.</span>
<span class="ansi-blue-fg">2020-09-04 18:13:27,188 sagemaker-containers INFO     Module train does not provide a setup.py. </span>
<span class="ansi-blue-fg">Generating setup.py</span>
<span class="ansi-blue-fg">2020-09-04 18:13:27,189 sagemaker-containers INFO     Generating setup.cfg</span>
<span class="ansi-blue-fg">2020-09-04 18:13:27,189 sagemaker-containers INFO     Generating MANIFEST.in</span>
<span class="ansi-blue-fg">2020-09-04 18:13:27,189 sagemaker-containers INFO     Installing module with the following command:</span>
<span class="ansi-blue-fg">/usr/bin/python -m pip install -U . -r requirements.txt</span>
<span class="ansi-blue-fg">Processing /opt/ml/code</span>
<span class="ansi-blue-fg">Collecting numpy (from -r requirements.txt (line 1))</span>
<span class="ansi-blue-fg">  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)</span>
<span class="ansi-blue-fg">Building wheels for collected packages: train
  Running setup.py bdist_wheel for train: started</span>
<span class="ansi-blue-fg">  Running setup.py bdist_wheel for train: finished with status 'done'
  Stored in directory: /tmp/pip-ephem-wheel-cache-7uiumycw/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3</span>
<span class="ansi-blue-fg">Successfully built train</span>
<span class="ansi-blue-fg">Installing collected packages: numpy, train
  Found existing installation: numpy 1.15.4
    Uninstalling numpy-1.15.4:</span>
<span class="ansi-blue-fg">      Successfully uninstalled numpy-1.15.4</span>

2020-09-04 18:13:22 Training - Training image download completed. Training in progress.<span class="ansi-blue-fg">Successfully installed numpy-1.18.5 train-1.0.0</span>
<span class="ansi-blue-fg">You are using pip version 18.1, however version 20.2.2 is available.</span>
<span class="ansi-blue-fg">You should consider upgrading via the 'pip install --upgrade pip' command.</span>
<span class="ansi-blue-fg">2020-09-04 18:13:34,112 sagemaker-containers INFO     Invoking user script
</span>
<span class="ansi-blue-fg">Training Env:
</span>
<span class="ansi-blue-fg">{
    "num_gpus": 1,
    "resource_config": {
        "network_interface_name": "eth0",
        "hosts": [
            "algo-1"
        ],
        "current_host": "algo-1"
    },
    "input_data_config": {
        "training": {
            "S3DistributionType": "FullyReplicated",
            "TrainingInputMode": "File",
            "RecordWrapperType": "None"
        }
    },
    "model_dir": "/opt/ml/model",
    "output_data_dir": "/opt/ml/output/data",
    "module_name": "train",
    "hosts": [
        "algo-1"
    ],
    "framework_module": "sagemaker_pytorch_container.training:main",
    "module_dir": "s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-04-18-09-12-678/source/sourcedir.tar.gz",
    "output_dir": "/opt/ml/output",
    "channel_input_dirs": {
        "training": "/opt/ml/input/data/training"
    },
    "num_cpus": 4,
    "network_interface_name": "eth0",
    "input_dir": "/opt/ml/input",
    "log_level": 20,
    "current_host": "algo-1",
    "user_entry_point": "train.py",
    "job_name": "sagemaker-pytorch-2020-09-04-18-09-12-678",
    "output_intermediate_dir": "/opt/ml/output/intermediate",
    "hyperparameters": {
        "epochs": 50,
        "hidden_dim": 512,
        "n_layers": 2
    },
    "additional_framework_parameters": {},
    "input_config_dir": "/opt/ml/input/config"</span>
<span class="ansi-blue-fg">}
</span>
<span class="ansi-blue-fg">Environment variables:
</span>
<span class="ansi-blue-fg">SM_USER_ENTRY_POINT=train.py</span>
<span class="ansi-blue-fg">SM_INPUT_CONFIG_DIR=/opt/ml/input/config</span>
<span class="ansi-blue-fg">SM_LOG_LEVEL=20</span>
<span class="ansi-blue-fg">SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main</span>
<span class="ansi-blue-fg">SM_RESOURCE_CONFIG={"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"}</span>
<span class="ansi-blue-fg">SM_OUTPUT_DATA_DIR=/opt/ml/output/data</span>
<span class="ansi-blue-fg">SM_CURRENT_HOST=algo-1</span>
<span class="ansi-blue-fg">SM_NUM_GPUS=1</span>
<span class="ansi-blue-fg">SM_HP_EPOCHS=50</span>
<span class="ansi-blue-fg">SM_HP_N_LAYERS=2</span>
<span class="ansi-blue-fg">SM_MODULE_NAME=train</span>
<span class="ansi-blue-fg">SM_TRAINING_ENV={"additional_framework_parameters":{},"channel_input_dirs":{"training":"/opt/ml/input/data/training"},"current_host":"algo-1","framework_module":"sagemaker_pytorch_container.training:main","hosts":["algo-1"],"hyperparameters":{"epochs":50,"hidden_dim":512,"n_layers":2},"input_config_dir":"/opt/ml/input/config","input_data_config":{"training":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}},"input_dir":"/opt/ml/input","job_name":"sagemaker-pytorch-2020-09-04-18-09-12-678","log_level":20,"model_dir":"/opt/ml/model","module_dir":"s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-04-18-09-12-678/source/sourcedir.tar.gz","module_name":"train","network_interface_name":"eth0","num_cpus":4,"num_gpus":1,"output_data_dir":"/opt/ml/output/data","output_dir":"/opt/ml/output","output_intermediate_dir":"/opt/ml/output/intermediate","resource_config":{"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"},"user_entry_point":"train.py"}</span>
<span class="ansi-blue-fg">SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate</span>
<span class="ansi-blue-fg">SM_OUTPUT_DIR=/opt/ml/output</span>
<span class="ansi-blue-fg">SM_INPUT_DATA_CONFIG={"training":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}}</span>
<span class="ansi-blue-fg">SM_FRAMEWORK_PARAMS={}</span>
<span class="ansi-blue-fg">SM_HOSTS=["algo-1"]</span>
<span class="ansi-blue-fg">SM_NUM_CPUS=4</span>
<span class="ansi-blue-fg">PYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages</span>
<span class="ansi-blue-fg">SM_CHANNELS=["training"]</span>
<span class="ansi-blue-fg">SM_MODEL_DIR=/opt/ml/model</span>
<span class="ansi-blue-fg">SM_CHANNEL_TRAINING=/opt/ml/input/data/training</span>
<span class="ansi-blue-fg">SM_HPS={"epochs":50,"hidden_dim":512,"n_layers":2}</span>
<span class="ansi-blue-fg">SM_HP_HIDDEN_DIM=512</span>
<span class="ansi-blue-fg">SM_INPUT_DIR=/opt/ml/input</span>
<span class="ansi-blue-fg">SM_NETWORK_INTERFACE_NAME=eth0</span>
<span class="ansi-blue-fg">SM_MODULE_DIR=s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-04-18-09-12-678/source/sourcedir.tar.gz</span>
<span class="ansi-blue-fg">SM_USER_ARGS=["--epochs","50","--hidden_dim","512","--n_layers","2"]
</span>
<span class="ansi-blue-fg">Invoking script with the following command:
</span>
<span class="ansi-blue-fg">/usr/bin/python -m train --epochs 50 --hidden_dim 512 --n_layers 2

</span>
<span class="ansi-blue-fg">Using device cuda.</span>
<span class="ansi-blue-fg">Get train data loader.</span>
<span class="ansi-blue-fg">Model loaded with embedding_dim 38, hidden_dim 512, vocab_size 38.</span>
<span class="ansi-blue-fg">Epoch: 1/50............. Time: 14.4431 Train Loss: 2.9868 Val Loss: 2.9684</span>
<span class="ansi-blue-fg">Epoch: 2/50............. Time: 14.4539 Train Loss: 2.8127 Val Loss: 2.5652</span>
<span class="ansi-blue-fg">Epoch: 3/50............. Time: 14.5240 Train Loss: 2.3785 Val Loss: 2.2880</span>
<span class="ansi-blue-fg">Epoch: 4/50............. Time: 14.6011 Train Loss: 2.1525 Val Loss: 2.0916</span>
<span class="ansi-blue-fg">Epoch: 5/50............. Time: 14.6164 Train Loss: 1.9958 Val Loss: 1.9362</span>
<span class="ansi-blue-fg">Epoch: 6/50............. Time: 14.6468 Train Loss: 1.8589 Val Loss: 1.8146</span>
<span class="ansi-blue-fg">Epoch: 7/50............. Time: 14.6547 Train Loss: 1.7433 Val Loss: 1.7126</span>
<span class="ansi-blue-fg">Epoch: 8/50............. Time: 14.6899 Train Loss: 1.6541 Val Loss: 1.6359</span>
<span class="ansi-blue-fg">Epoch: 9/50............. Time: 14.6877 Train Loss: 1.5832 Val Loss: 1.5861</span>
<span class="ansi-blue-fg">Epoch: 10/50............. Time: 14.9234 Train Loss: 1.5350 Val Loss: 1.5421</span>
<span class="ansi-blue-fg">Epoch: 11/50............. Time: 14.7145 Train Loss: 1.6048 Val Loss: 1.5478</span>
<span class="ansi-blue-fg">Epoch: 12/50............. Time: 14.8416 Train Loss: 1.4783 Val Loss: 1.4964</span>
<span class="ansi-blue-fg">Epoch: 13/50............. Time: 14.6023 Train Loss: 1.4303 Val Loss: 1.4738</span>
<span class="ansi-blue-fg">Epoch: 14/50............. Time: 14.6174 Train Loss: 1.3992 Val Loss: 1.4667</span>
<span class="ansi-blue-fg">Epoch: 15/50............. Time: 14.8158 Train Loss: 1.3759 Val Loss: 1.4611</span>
<span class="ansi-blue-fg">Epoch: 16/50............. Time: 15.3926 Train Loss: 1.3576 Val Loss: 1.4520</span>
<span class="ansi-blue-fg">Epoch: 17/50............. Time: 15.4225 Train Loss: 1.3431 Val Loss: 1.4551</span>
<span class="ansi-blue-fg">Epoch: 18/50............. Time: 15.7483 Train Loss: 1.3301 Val Loss: 1.4477</span>
<span class="ansi-blue-fg">Epoch: 19/50............. Time: 15.5521 Train Loss: 1.3183 Val Loss: 1.4493</span>
<span class="ansi-blue-fg">Epoch: 20/50............. Time: 15.5506 Train Loss: 1.3071 Val Loss: 1.4519</span>
<span class="ansi-blue-fg">Epoch: 21/50............. Time: 15.8857 Train Loss: 1.2994 Val Loss: 1.4560</span>
<span class="ansi-blue-fg">Epoch: 22/50............. Time: 15.8872 Train Loss: 1.2918 Val Loss: 1.4624</span>
<span class="ansi-blue-fg">Epoch: 23/50............. Time: 15.5845 Train Loss: 1.2837 Val Loss: 1.4590</span>
<span class="ansi-blue-fg">Epoch: 24/50............. Time: 15.4095 Train Loss: 1.2769 Val Loss: 1.4608</span>
<span class="ansi-blue-fg">Epoch: 25/50............. Time: 15.3529 Train Loss: 1.2723 Val Loss: 1.4590</span>
<span class="ansi-blue-fg">Epoch: 26/50............. Time: 15.4680 Train Loss: 1.2655 Val Loss: 1.4589</span>
<span class="ansi-blue-fg">Epoch: 27/50............. Time: 15.2459 Train Loss: 1.2594 Val Loss: 1.4576</span>
<span class="ansi-blue-fg">Epoch: 28/50............. Time: 14.8407 Train Loss: 1.2541 Val Loss: 1.4611</span>
<span class="ansi-blue-fg">Epoch: 29/50............. Time: 14.8493 Train Loss: 1.2491 Val Loss: 1.4626</span>
<span class="ansi-blue-fg">Epoch: 30/50............. Time: 14.8030 Train Loss: 1.2439 Val Loss: 1.4673</span>
<span class="ansi-blue-fg">Epoch: 31/50............. Time: 14.8256 Train Loss: 1.2406 Val Loss: 1.4672</span>
<span class="ansi-blue-fg">Epoch: 32/50............. Time: 14.8147 Train Loss: 1.2360 Val Loss: 1.4802</span>
<span class="ansi-blue-fg">Epoch: 33/50............. Time: 14.8162 Train Loss: 1.2309 Val Loss: 1.4683</span>
<span class="ansi-blue-fg">Epoch: 34/50............. Time: 14.7752 Train Loss: 1.2273 Val Loss: 1.4689</span>
<span class="ansi-blue-fg">Epoch: 35/50............. Time: 14.8036 Train Loss: 1.2238 Val Loss: 1.4734</span>
<span class="ansi-blue-fg">Epoch: 36/50............. Time: 14.9146 Train Loss: 1.2201 Val Loss: 1.4775</span>
<span class="ansi-blue-fg">Epoch: 37/50............. Time: 14.7848 Train Loss: 1.2188 Val Loss: 1.4706</span>
<span class="ansi-blue-fg">Epoch: 38/50............. Time: 14.8986 Train Loss: 1.2141 Val Loss: 1.4750</span>
<span class="ansi-blue-fg">Epoch: 39/50............. Time: 15.3889 Train Loss: 1.2104 Val Loss: 1.4759</span>
<span class="ansi-blue-fg">Epoch: 40/50............. Time: 15.4683 Train Loss: 1.2065 Val Loss: 1.4744</span>
<span class="ansi-blue-fg">Epoch: 41/50............. Time: 14.8328 Train Loss: 1.2049 Val Loss: 1.4741</span>
<span class="ansi-blue-fg">Epoch: 42/50............. Time: 14.8112 Train Loss: 1.2023 Val Loss: 1.4774</span>
<span class="ansi-blue-fg">Epoch: 43/50............. Time: 14.8114 Train Loss: 1.1987 Val Loss: 1.4803</span>
<span class="ansi-blue-fg">Epoch: 44/50............. Time: 14.7854 Train Loss: 1.1956 Val Loss: 1.4837</span>
<span class="ansi-blue-fg">Epoch: 45/50............. Time: 14.8066 Train Loss: 1.1929 Val Loss: 1.4888</span>
<span class="ansi-blue-fg">Epoch: 46/50............. Time: 14.9014 Train Loss: 1.1889 Val Loss: 1.4856</span>
<span class="ansi-blue-fg">Epoch: 47/50............. Time: 14.7856 Train Loss: 1.1877 Val Loss: 1.4897</span>
<span class="ansi-blue-fg">Epoch: 48/50............. Time: 14.7771 Train Loss: 1.1857 Val Loss: 1.4911</span>
<span class="ansi-blue-fg">Epoch: 49/50............. Time: 15.2428 Train Loss: 1.1826 Val Loss: 1.4963</span>

2020-09-04 18:26:23 Uploading - Uploading generated training model
2020-09-04 18:26:23 Completed - Training job completed
<span class="ansi-blue-fg">Epoch: 50/50............. Time: 15.3424 Train Loss: 1.1790 Val Loss: 1.4912</span>
<span class="ansi-blue-fg">2020-09-04 18:26:12,138 sagemaker-containers INFO     Reporting training SUCCESS</span>
Training seconds: 852
Billable seconds: 852
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-5:-Testing-the-model">
<a class="anchor" href="#Step-5:-Testing-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 5: Testing the model<a class="anchor-link" href="#Step-5:-Testing-the-model"> </a>
</h2>
<p>As mentioned at the top of this notebook, we will be testing this model by first deploying it and then sending the testing data to the deployed endpoint. We will do this so that we can make sure that the deployed model is working correctly.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-6---Deploy-the-model-for-inference">
<a class="anchor" href="#Step-6---Deploy-the-model-for-inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 6 - Deploy the model for inference<a class="anchor-link" href="#Step-6---Deploy-the-model-for-inference"> </a>
</h2>
<p>Now that our model is trained, it's time to create some custom inference code so that we can send the model a initial string which has not been processed and determine the next caracters on the string.</p>
<p>By default the estimator which we created, when deployed, will use the entry script and directory which we provided when creating the model. However, since we wish to accept a string as input and our model expects a processed review, we need to write some custom inference code.</p>
<p>We will store the code that we write in the <code>serve</code> directory. Provided in this directory is the <code>model.py</code> file that we used to construct our model, a <code>utils.py</code> file which contains the <code>one-hot-encode</code> and <code>encode_text</code> pre-processing functions which we used during the initial data processing, and <code>predict.py</code>, the file which will contain our custom inference code. Note also that <code>requirements.txt</code> is present which will tell SageMaker what Python libraries are required by our custom inference code.</p>
<p>When deploying a PyTorch model in SageMaker, you are expected to provide four functions which the SageMaker inference container will use.</p>
<ul>
<li>
<code>model_fn</code>: This function is the same function that we used in the training script and it tells SageMaker how to load our model. This function must be called <code>model_fn()</code> and takes as its only parameter a path to the directory where the model artifacts are stored. This function must also be present in the python file which we specified as the entry point. It also reads the saved dictionaries because they could be used during the inference process.</li>
<li>
<code>input_fn</code>: This function receives the raw serialized input that has been sent to the model's endpoint and its job is to de-serialize and make the input available for the inference code. Latter we will mention what our input_fn function is doing.</li>
<li>
<code>output_fn</code>: This function takes the output of the inference code and its job is to serialize this output and return it to the caller of the model's endpoint.</li>
<li>
<code>predict_fn</code>: The heart of the inference script, this is where the actual prediction is done and is the function which you will need to complete.</li>
</ul>
<p>For the simple example that we are constructing during this project, the <code>input_fn</code> and <code>output_fn</code> methods are relatively straightforward. We require being able to accept a string as input, <em>composed by the desired length of the output and the initial string</em>. And we expect to return a single string as output, the new text generated. You might imagine though that in a more complex application the input or output may be image data or some other binary data which would require some effort to serialize.</p>
<h3 id="Writing-inference-code">
<a class="anchor" href="#Writing-inference-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing inference code<a class="anchor-link" href="#Writing-inference-code"> </a>
</h3>
<p>Before writing our custom inference code, we will begin by taking a look at the code which has been provided.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pygmentize serve/predict.py
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">argparse</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">json</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">os</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">pickle</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">sys</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">sagemaker_containers</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">numpy</span> <span class="ansi-blue-fg">as</span> <span class="ansi-cyan-fg ansi-underline">np</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">torch</span>
<span class="ansi-blue-fg">import</span> <span class="ansi-cyan-fg ansi-underline">torch</span><span class="ansi-cyan-fg ansi-underline">.</span><span class="ansi-cyan-fg ansi-underline">nn</span> <span class="ansi-blue-fg">as</span> <span class="ansi-cyan-fg ansi-underline">nn</span>

<span class="ansi-blue-fg">from</span> <span class="ansi-cyan-fg ansi-underline">model</span> <span class="ansi-blue-fg">import</span> RNNModel

<span class="ansi-blue-fg">from</span> <span class="ansi-cyan-fg ansi-underline">utils</span> <span class="ansi-blue-fg">import</span> clean_text, encode_text, one_hot_encode

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">model_fn</span>(model_dir):
    <span class="ansi-yellow-fg">"""Load the PyTorch model from the `model_dir` directory."""</span>
    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">Loading model.</span><span class="ansi-yellow-fg">"</span>)

    <span class="ansi-white-fg"># First, load the parameters used to create the model.</span>
    model_info = {}
    model_info_path = os.path.join(model_dir, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">model_info.pth</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">with</span> <span class="ansi-cyan-fg">open</span>(model_info_path, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">rb</span><span class="ansi-yellow-fg">'</span>) <span class="ansi-blue-fg">as</span> f:
        model_info = torch.load(f)

    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">model_info: </span><span class="ansi-yellow-fg">{}</span><span class="ansi-yellow-fg">"</span>.format(model_info))

    <span class="ansi-white-fg"># Determine the device and construct the model.</span>
    device = torch.device(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cuda</span><span class="ansi-yellow-fg">"</span> <span class="ansi-blue-fg">if</span> torch.cuda.is_available() <span class="ansi-blue-fg">else</span> <span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cpu</span><span class="ansi-yellow-fg">"</span>)
    model = RNNModel(model_info[<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">vocab_size</span><span class="ansi-yellow-fg">'</span>], model_info[<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">embedding_dim</span><span class="ansi-yellow-fg">'</span>], model_info[<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">hidden_dim</span><span class="ansi-yellow-fg">'</span>], model_info[<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">n_layers</span><span class="ansi-yellow-fg">'</span>], model_info[<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">drop_rate</span><span class="ansi-yellow-fg">'</span>])

    <span class="ansi-white-fg"># Load the stored model parameters.</span>
    model_path = os.path.join(model_dir, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">model.pth</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">with</span> <span class="ansi-cyan-fg">open</span>(model_path, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">rb</span><span class="ansi-yellow-fg">'</span>) <span class="ansi-blue-fg">as</span> f:
        model.load_state_dict(torch.load(f, map_location=<span class="ansi-blue-fg">lambda</span> storage, loc: storage))

    <span class="ansi-white-fg"># Load the saved word_dict.</span>
    word_dict_path = os.path.join(model_dir, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">char_dict.pkl</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">with</span> <span class="ansi-cyan-fg">open</span>(word_dict_path, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">rb</span><span class="ansi-yellow-fg">'</span>) <span class="ansi-blue-fg">as</span> f:
        model.char2int = pickle.load(f)

    word_dict_path = os.path.join(model_dir, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">int_dict.pkl</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">with</span> <span class="ansi-cyan-fg">open</span>(word_dict_path, <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">rb</span><span class="ansi-yellow-fg">'</span>) <span class="ansi-blue-fg">as</span> f:
        model.int2char = pickle.load(f)

    model.to(device).eval()

    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">Done loading model.</span><span class="ansi-yellow-fg">"</span>)
    <span class="ansi-blue-fg">return</span> model

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">input_fn</span>(serialized_input_data, content_type):
    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Deserializing the input data.</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">if</span> content_type == <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">text/plain</span><span class="ansi-yellow-fg">'</span>:
        data = serialized_input_data.decode(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">utf-8</span><span class="ansi-yellow-fg">'</span>)
        <span class="ansi-white-fg"># Extract the desired length of the output string</span>
        sep_pos= data.find(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">-</span><span class="ansi-yellow-fg">'</span>)
        <span class="ansi-blue-fg">if</span> sep_pos &gt; <span class="ansi-blue-fg">0</span>:
            length = data[:sep_pos]
            initial_string = data[sep_pos+<span class="ansi-blue-fg">1</span>:]
        <span class="ansi-blue-fg">return</span> (length,initial_string)
    <span class="ansi-blue-fg">raise</span> <span class="ansi-cyan-fg">Exception</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Requested unsupported ContentType in content_type: </span><span class="ansi-yellow-fg">'</span> + content_type)

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">output_fn</span>(prediction_output, accept):
    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Serializing the generated output.</span><span class="ansi-yellow-fg">'</span>)
    <span class="ansi-blue-fg">return</span> <span class="ansi-cyan-fg">str</span>(prediction_output)

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">sample_from_probs</span>(probs, top_n=<span class="ansi-blue-fg">10</span>):
    <span class="ansi-yellow-fg">"""</span>
<span class="ansi-yellow-fg">    truncated weighted random choice.</span>
<span class="ansi-yellow-fg">    """</span>
    _, indices = torch.sort(probs)
    <span class="ansi-white-fg"># set probabilities after top_n to 0</span>
    probs[indices.data[:-top_n]] = <span class="ansi-blue-fg">0</span>
    <span class="ansi-white-fg">#print(probs.shape)</span>
    sampled_index = torch.multinomial(probs, <span class="ansi-blue-fg">1</span>)
    <span class="ansi-blue-fg">return</span> sampled_index

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">predict_probs</span>(model, hidden, character, vocab, device):
    <span class="ansi-white-fg"># One-hot encoding our input to fit into the model</span>
    character = np.array([[vocab[c] <span class="ansi-blue-fg">for</span> c <span class="ansi-magenta-fg">in</span> character]])
    character = one_hot_encode(character, <span class="ansi-cyan-fg">len</span>(vocab))
    character = torch.from_numpy(character)
    character = character.to(device)
    
    <span class="ansi-blue-fg">with</span> torch.no_grad():
        out, hidden = model(character, hidden)

    prob = nn.functional.softmax(out[-<span class="ansi-blue-fg">1</span>], dim=<span class="ansi-blue-fg">0</span>).data

    <span class="ansi-blue-fg">return</span> prob, hidden

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">predict_old</span>(input_data, model):
    <span class="ansi-cyan-fg">print</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Inferring sentiment of input data.</span><span class="ansi-yellow-fg">'</span>)

    device = torch.device(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cuda</span><span class="ansi-yellow-fg">"</span> <span class="ansi-blue-fg">if</span> torch.cuda.is_available() <span class="ansi-blue-fg">else</span> <span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cpu</span><span class="ansi-yellow-fg">"</span>)
    
    <span class="ansi-blue-fg">if</span> model.char2int <span class="ansi-magenta-fg">is</span> <span class="ansi-blue-fg">None</span>:
        <span class="ansi-blue-fg">raise</span> <span class="ansi-cyan-fg">Exception</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Model has not been loaded properly, no word_dict.</span><span class="ansi-yellow-fg">'</span>)
    
    model.eval() <span class="ansi-white-fg"># eval mode</span>
    start = input_data.lower()
    <span class="ansi-white-fg"># Clean the text as the text used in training </span>
    start = clean_text(start, <span class="ansi-blue-fg">True</span>)
    <span class="ansi-white-fg"># Encode the text</span>
    <span class="ansi-white-fg">#encode_text(start, model.vocab, one_hot = False):</span>
    <span class="ansi-white-fg"># First off, run through the starting characters</span>
    chars = [ch <span class="ansi-blue-fg">for</span> ch <span class="ansi-magenta-fg">in</span> start]

    state = model.init_state(device, <span class="ansi-blue-fg">1</span>)
    probs, state = predict_probs(model, state, chars, model.vocab, device)
    <span class="ansi-white-fg">#print(probs.shape)</span>
    <span class="ansi-white-fg">#probs = torch.transpose(probs, 0, 1)</span>
    next_index = sample_from_probs(probs[-<span class="ansi-blue-fg">1</span>].squeeze(), top_n=<span class="ansi-blue-fg">3</span>)
    
    <span class="ansi-blue-fg">return</span> next_index.data[<span class="ansi-blue-fg">0</span>].item()

<span class="ansi-blue-fg">def</span> <span class="ansi-green-fg">predict_fn</span>(input_data, model):

    device = torch.device(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cuda</span><span class="ansi-yellow-fg">"</span> <span class="ansi-blue-fg">if</span> torch.cuda.is_available() <span class="ansi-blue-fg">else</span> <span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">cpu</span><span class="ansi-yellow-fg">"</span>)
    
    <span class="ansi-blue-fg">if</span> model.char2int <span class="ansi-magenta-fg">is</span> <span class="ansi-blue-fg">None</span>:
        <span class="ansi-blue-fg">raise</span> <span class="ansi-cyan-fg">Exception</span>(<span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">Model has not been loaded properly, no word_dict.</span><span class="ansi-yellow-fg">'</span>)
    
    <span class="ansi-white-fg"># TODO: Process input_data so that it is ready to be sent to our model.</span>
    <span class="ansi-white-fg">#       You should produce two variables:</span>
    <span class="ansi-white-fg">#         data_X   - A sequence of length 500 which represents the converted review</span>
    <span class="ansi-white-fg">#         data_len - The length of the review</span>
    <span class="ansi-white-fg"># Extract the input data and the desired length</span>
    out_len, start = input_data
    out_len = <span class="ansi-cyan-fg">int</span>(out_len)

    model.eval() <span class="ansi-white-fg"># eval mode</span>
    start = start.lower()
    <span class="ansi-white-fg"># Clean the text as the text used in training </span>
    start = clean_text(start, <span class="ansi-blue-fg">True</span>)
    <span class="ansi-white-fg"># First off, run through the starting characters</span>
    chars = [ch <span class="ansi-blue-fg">for</span> ch <span class="ansi-magenta-fg">in</span> start]
    size = out_len - <span class="ansi-cyan-fg">len</span>(chars)
    <span class="ansi-white-fg"># Init the hidden state</span>
    state = model.init_state(device, <span class="ansi-blue-fg">1</span>)

    <span class="ansi-white-fg"># Warm up the initial state, predicting on the initial string</span>
    <span class="ansi-blue-fg">for</span> ch <span class="ansi-magenta-fg">in</span> chars:
        <span class="ansi-white-fg">#char, state = predict(model, ch, state, top_n=top_k)</span>
        probs, state = predict_probs(model, state, ch, model.char2int, device)
        next_index = sample_from_probs(probs, <span class="ansi-blue-fg">5</span>)

    <span class="ansi-white-fg"># Include the last char predicted to the predicted output</span>
    chars.append(model.int2char[next_index.data[<span class="ansi-blue-fg">0</span>]])   
    <span class="ansi-white-fg"># Now pass in the previous characters and get a new one</span>
    <span class="ansi-blue-fg">for</span> ii <span class="ansi-magenta-fg">in</span> <span class="ansi-cyan-fg">range</span>(size-<span class="ansi-blue-fg">1</span>):
        <span class="ansi-white-fg">#char, h = predict_char(model, chars, vocab)</span>
        probs, state = predict_probs(model, state, chars[-<span class="ansi-blue-fg">1</span>], model.char2int, device)
        next_index = sample_from_probs(probs, <span class="ansi-blue-fg">5</span>)
        <span class="ansi-white-fg"># append to sequence</span>
        chars.append(model.int2char[next_index.data[<span class="ansi-blue-fg">0</span>]])

    <span class="ansi-white-fg"># Join all the chars    </span>
    <span class="ansi-white-fg">#chars = chars.decode('utf-8')</span>
    <span class="ansi-blue-fg">return</span> <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">'</span>.join(chars)
    
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As mentioned earlier, the <code>model_fn</code> method is the same as the one provided in the training code and the <code>input_fn</code> and <code>output_fn</code> methods are very simple. Finally we must build a <code>predict_fn</code> method that will receive the input string, encode it (char2int), one-hot-encode and send it to the model. Every output will be decode (int2char) and appended to the final output string.</p>
<p>Make sure that you save the completed file as <code>predict.py</code> in the <code>serve</code> directory.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Deploying-the-model">
<a class="anchor" href="#Deploying-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deploying the model<a class="anchor-link" href="#Deploying-the-model"> </a>
</h3>
<p>Now that the custom inference code has been written, we will create and deploy our model. To begin with, we need to construct a new PyTorchModel object which points to the model artifacts created during training and also points to the inference code that we wish to use. Then we can call the deploy method to launch the deployment container.</p>
<p><strong>NOTE</strong>: The default behaviour for a deployed PyTorch model is to assume that any input passed to the predictor is a <code>numpy</code> array. In our case we want to send a string so we need to construct a simple wrapper around the <code>RealTimePredictor</code> class to accomodate simple strings. In a more complicated situation you may want to provide a serialization object, for example if you wanted to sent image data.</p>
<p><strong>NOTE:</strong> When deploying a model you are asking SageMaker to launch an compute instance that will wait for data to be sent to it. As a result, this compute instance will continue to run until <em>you</em> shut it down. This is important to know since the cost of a deployed endpoint depends on how long it has been running for.</p>
<p>In other words <strong>If you are no longer using a deployed endpoint, shut it down!</strong></p>
<p>Now, we can deploy our trained model</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Loading-a-previously-trained-model">
<a class="anchor" href="#Loading-a-previously-trained-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading a previously trained model<a class="anchor-link" href="#Loading-a-previously-trained-model"> </a>
</h3>
<p>In many situations, you have trained the model in another execution of this notebook or you shutdown the notebook while the model was training. So the estimator variable is empty or undefined and then, you want to restore or use a previous training job and deploy it. In the next cell, we attach that trained model to the estimator variable and continue the necessary steps to launch and deploy the model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Attach the estimator to a oreviously trained job</span>
<span class="kn">from</span> <span class="nn">sagemaker.pytorch</span> <span class="kn">import</span> <span class="n">PyTorch</span>

<span class="n">my_training_job_name</span> <span class="o">=</span> <span class="s1">'sagemaker-pytorch-2020-09-02-19-49-57-475'</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">PyTorch</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">my_training_job_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2020-09-02 20:00:18 Starting - Preparing the instances for training
2020-09-02 20:00:18 Downloading - Downloading input data
2020-09-02 20:00:18 Training - Training image download completed. Training in progress.
2020-09-02 20:00:18 Uploading - Uploading generated training model
2020-09-02 20:00:18 Completed - Training job completed<span class="ansi-blue-fg">bash: cannot set terminal process group (-1): Inappropriate ioctl for device</span>
<span class="ansi-blue-fg">bash: no job control in this shell</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,432 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,457 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,461 sagemaker_pytorch_container.training INFO     Invoking user training script.</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,761 sagemaker-containers INFO     Module train does not provide a setup.py. </span>
<span class="ansi-blue-fg">Generating setup.py</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,761 sagemaker-containers INFO     Generating setup.cfg</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,761 sagemaker-containers INFO     Generating MANIFEST.in</span>
<span class="ansi-blue-fg">2020-09-02 19:53:51,761 sagemaker-containers INFO     Installing module with the following command:</span>
<span class="ansi-blue-fg">/usr/bin/python -m pip install -U . -r requirements.txt</span>
<span class="ansi-blue-fg">Processing /opt/ml/code</span>
<span class="ansi-blue-fg">Collecting pandas (from -r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)</span>
<span class="ansi-blue-fg">Collecting numpy (from -r requirements.txt (line 2))</span>
<span class="ansi-blue-fg">  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)</span>
<span class="ansi-blue-fg">Collecting pytz&gt;=2011k (from pandas-&gt;-r requirements.txt (line 1))
  Downloading https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl (510kB)</span>
<span class="ansi-blue-fg">Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas-&gt;-r requirements.txt (line 1)) (2.7.5)</span>
<span class="ansi-blue-fg">Requirement already satisfied, skipping upgrade: six&gt;=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil&gt;=2.5.0-&gt;pandas-&gt;-r requirements.txt (line 1)) (1.11.0)</span>
<span class="ansi-blue-fg">Building wheels for collected packages: train
  Running setup.py bdist_wheel for train: started</span>
<span class="ansi-blue-fg">  Running setup.py bdist_wheel for train: finished with status 'done'
  Stored in directory: /tmp/pip-ephem-wheel-cache-9xt478wn/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3</span>
<span class="ansi-blue-fg">Successfully built train</span>
<span class="ansi-blue-fg">Installing collected packages: pytz, numpy, pandas, train
  Found existing installation: numpy 1.15.4
    Uninstalling numpy-1.15.4:</span>
<span class="ansi-blue-fg">      Successfully uninstalled numpy-1.15.4</span>
<span class="ansi-blue-fg">Successfully installed numpy-1.18.5 pandas-0.24.2 pytz-2020.1 train-1.0.0</span>
<span class="ansi-blue-fg">You are using pip version 18.1, however version 20.2.2 is available.</span>
<span class="ansi-blue-fg">You should consider upgrading via the 'pip install --upgrade pip' command.</span>
<span class="ansi-blue-fg">2020-09-02 19:54:01,620 sagemaker-containers INFO     Invoking user script
</span>
<span class="ansi-blue-fg">Training Env:
</span>
<span class="ansi-blue-fg">{
    "output_dir": "/opt/ml/output",
    "log_level": 20,
    "network_interface_name": "eth0",
    "hosts": [
        "algo-1"
    ],
    "job_name": "sagemaker-pytorch-2020-09-02-19-49-57-475",
    "num_cpus": 4,
    "user_entry_point": "train.py",
    "module_dir": "s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-02-19-49-57-475/source/sourcedir.tar.gz",
    "framework_module": "sagemaker_pytorch_container.training:main",
    "input_dir": "/opt/ml/input",
    "output_intermediate_dir": "/opt/ml/output/intermediate",
    "input_data_config": {
        "training": {
            "TrainingInputMode": "File",
            "S3DistributionType": "FullyReplicated",
            "RecordWrapperType": "None"
        }
    },
    "hyperparameters": {
        "epochs": 3,
        "hidden_dim": 64
    },
    "output_data_dir": "/opt/ml/output/data",
    "model_dir": "/opt/ml/model",
    "channel_input_dirs": {
        "training": "/opt/ml/input/data/training"
    },
    "resource_config": {
        "network_interface_name": "eth0",
        "hosts": [
            "algo-1"
        ],
        "current_host": "algo-1"
    },
    "num_gpus": 1,
    "input_config_dir": "/opt/ml/input/config",
    "additional_framework_parameters": {},
    "module_name": "train",
    "current_host": "algo-1"</span>
<span class="ansi-blue-fg">}
</span>
<span class="ansi-blue-fg">Environment variables:
</span>
<span class="ansi-blue-fg">SM_LOG_LEVEL=20</span>
<span class="ansi-blue-fg">SM_HP_EPOCHS=3</span>
<span class="ansi-blue-fg">SM_FRAMEWORK_PARAMS={}</span>
<span class="ansi-blue-fg">SM_HPS={"epochs":3,"hidden_dim":64}</span>
<span class="ansi-blue-fg">SM_NUM_CPUS=4</span>
<span class="ansi-blue-fg">SM_OUTPUT_DATA_DIR=/opt/ml/output/data</span>
<span class="ansi-blue-fg">SM_TRAINING_ENV={"additional_framework_parameters":{},"channel_input_dirs":{"training":"/opt/ml/input/data/training"},"current_host":"algo-1","framework_module":"sagemaker_pytorch_container.training:main","hosts":["algo-1"],"hyperparameters":{"epochs":3,"hidden_dim":64},"input_config_dir":"/opt/ml/input/config","input_data_config":{"training":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}},"input_dir":"/opt/ml/input","job_name":"sagemaker-pytorch-2020-09-02-19-49-57-475","log_level":20,"model_dir":"/opt/ml/model","module_dir":"s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-02-19-49-57-475/source/sourcedir.tar.gz","module_name":"train","network_interface_name":"eth0","num_cpus":4,"num_gpus":1,"output_data_dir":"/opt/ml/output/data","output_dir":"/opt/ml/output","output_intermediate_dir":"/opt/ml/output/intermediate","resource_config":{"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"},"user_entry_point":"train.py"}</span>
<span class="ansi-blue-fg">PYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages</span>
<span class="ansi-blue-fg">SM_CHANNEL_TRAINING=/opt/ml/input/data/training</span>
<span class="ansi-blue-fg">SM_INPUT_DIR=/opt/ml/input</span>
<span class="ansi-blue-fg">SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main</span>
<span class="ansi-blue-fg">SM_NUM_GPUS=1</span>
<span class="ansi-blue-fg">SM_INPUT_CONFIG_DIR=/opt/ml/input/config</span>
<span class="ansi-blue-fg">SM_USER_ARGS=["--epochs","3","--hidden_dim","64"]</span>
<span class="ansi-blue-fg">SM_INPUT_DATA_CONFIG={"training":{"RecordWrapperType":"None","S3DistributionType":"FullyReplicated","TrainingInputMode":"File"}}</span>
<span class="ansi-blue-fg">SM_USER_ENTRY_POINT=train.py</span>
<span class="ansi-blue-fg">SM_OUTPUT_DIR=/opt/ml/output</span>
<span class="ansi-blue-fg">SM_CURRENT_HOST=algo-1</span>
<span class="ansi-blue-fg">SM_MODULE_DIR=s3://sagemaker-us-east-1-223817798831/sagemaker-pytorch-2020-09-02-19-49-57-475/source/sourcedir.tar.gz</span>
<span class="ansi-blue-fg">SM_MODEL_DIR=/opt/ml/model</span>
<span class="ansi-blue-fg">SM_CHANNELS=["training"]</span>
<span class="ansi-blue-fg">SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate</span>
<span class="ansi-blue-fg">SM_NETWORK_INTERFACE_NAME=eth0</span>
<span class="ansi-blue-fg">SM_MODULE_NAME=train</span>
<span class="ansi-blue-fg">SM_HP_HIDDEN_DIM=64</span>
<span class="ansi-blue-fg">SM_RESOURCE_CONFIG={"current_host":"algo-1","hosts":["algo-1"],"network_interface_name":"eth0"}</span>
<span class="ansi-blue-fg">SM_HOSTS=["algo-1"]
</span>
<span class="ansi-blue-fg">Invoking script with the following command:
</span>
<span class="ansi-blue-fg">/usr/bin/python -m train --epochs 3 --hidden_dim 64

</span>
<span class="ansi-blue-fg">Using device cuda.</span>
<span class="ansi-blue-fg">Get train data loader.</span>
<span class="ansi-blue-fg">Model loaded with embedding_dim 28, hidden_dim 64, vocab_size 28.</span>
<span class="ansi-blue-fg">Epoch: 1/3............. Loss: 1.5655</span>
<span class="ansi-blue-fg">Epoch: 2/3............. Loss: 1.5143</span>
<span class="ansi-blue-fg">Epoch: 3/3............. Loss: 1.5086</span>
<span class="ansi-blue-fg">2020-09-02 20:00:09,820 sagemaker-containers INFO     Reporting training SUCCESS</span>
Training seconds: 453
Billable seconds: 453
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sagemaker.predictor</span> <span class="kn">import</span> <span class="n">RealTimePredictor</span>
<span class="kn">from</span> <span class="nn">sagemaker.pytorch</span> <span class="kn">import</span> <span class="n">PyTorchModel</span>

<span class="k">class</span> <span class="nc">StringPredictor</span><span class="p">(</span><span class="n">RealTimePredictor</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">endpoint_name</span><span class="p">,</span> <span class="n">sagemaker_session</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StringPredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">endpoint_name</span><span class="p">,</span> <span class="n">sagemaker_session</span><span class="p">,</span> <span class="n">content_type</span><span class="o">=</span><span class="s1">'text/plain'</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PyTorchModel</span><span class="p">(</span><span class="n">model_data</span><span class="o">=</span><span class="n">estimator</span><span class="o">.</span><span class="n">model_data</span><span class="p">,</span>
                     <span class="n">role</span> <span class="o">=</span> <span class="n">role</span><span class="p">,</span>
                     <span class="n">framework_version</span><span class="o">=</span><span class="s1">'0.4.0'</span><span class="p">,</span>
                     <span class="n">entry_point</span><span class="o">=</span><span class="s1">'predict.py'</span><span class="p">,</span>
                     <span class="n">source_dir</span><span class="o">=</span><span class="s1">'serve'</span><span class="p">,</span>
                     <span class="n">predictor_cls</span><span class="o">=</span><span class="n">StringPredictor</span><span class="p">)</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="n">initial_instance_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">instance_type</span><span class="o">=</span><span class="s1">'ml.m4.xlarge'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Parameter image will be renamed to image_uri in SageMaker Python SDK v2.
'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>---------------!</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-7---Use-the-model-for-testing">
<a class="anchor" href="#Step-7---Use-the-model-for-testing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Step 7 - Use the model for testing<a class="anchor-link" href="#Step-7---Use-the-model-for-testing"> </a>
</h2>
<p>Now that we have deployed our model with the custom inference code, we should test it to see if everything is working. Here we test our model by creating an initial string and send it to the endpoint, then collect the result. But we also want to tell the inference how long should be the expected output.</p>
<p>It means that we need to send to our predict function not only the initial string but the the length of the output. As the expected input by the deserialized function, input_fn, is a string and we are looking for a simple solution, <strong>our input data will be a string composed by: the length of the output+'-'+initial string.</strong></p>
<p>Now, it is time to test our model, sending a very common initial string: <code>you are</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_text</span> <span class="o">=</span> <span class="s1">'100-you are '</span>
<span class="n">new_text</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>you are think too the starry a my seens weeped as he to be then that tonight we was shall be wear my
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another example to try out is to send the model a text included in the training dataset and see what the model predicts:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Text: '</span><span class="p">,</span><span class="n">sentences</span><span class="p">[</span><span class="mi">963</span><span class="p">:</span><span class="mi">1148</span><span class="p">])</span>
<span class="n">init_text</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="mi">963</span><span class="p">:</span><span class="mi">1148</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Init text: '</span><span class="p">,</span> <span class="n">sentences</span><span class="p">[</span><span class="mi">963</span><span class="p">:</span><span class="mi">1020</span><span class="p">])</span>
<span class="n">test_text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">init_text</span><span class="p">))</span><span class="o">+</span><span class="s1">'-'</span><span class="o">+</span><span class="n">init_text</span>
<span class="n">new_text</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Text:  he did content to say it was for his country he did it to please his mother and to be partly proud; which he is, even till the altitude of his virtue. what he cannot help in his nature,
Init text:  he did content to say it was for his country he did it to
he did content to say it was for his country he did it to please his mother and to be partly proud which he is even till the altitude of his virtue what he cannot help in his nature of 
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can check that the model "remember" the texts during the training, it can mostly reproduce the original text.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we know our endpoint is working as expected, we can set up a web page or app that will interact with it.</p>
<p><strong>Make sure to skip down to the end of this notebook and shut down your endpoint. You can deploy it again when you come back.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Delete-the-endpoint">
<a class="anchor" href="#Delete-the-endpoint" aria-hidden="true"><span class="octicon octicon-link"></span></a>Delete the endpoint<a class="anchor-link" href="#Delete-the-endpoint"> </a>
</h3>
<p>Remember to always shut down your endpoint if you are no longer using it. You are charged for the length of time that the endpoint is running so if you forget and leave it on you could end up with an unexpectedly large bill.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictor</span><span class="o">.</span><span class="n">delete_endpoint</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/BlogEms/fastpages/jupyter/rnn/lstm/pytorch/sagemaker/2020/09/06/char-level-text-generator-pytorch-SageMaker.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/BlogEms/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/BlogEms/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/BlogEms/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/edumunozsala" title="edumunozsala"><svg class="svg-icon grey"><use xlink:href="/BlogEms/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/emunozsala" title="emunozsala"><svg class="svg-icon grey"><use xlink:href="/BlogEms/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
